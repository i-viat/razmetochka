import streamlit as st
import pandas as pd
import pickle
import matplotlib.pyplot as plt
import random
import seaborn as sns
import matplotlib.ticker as ticker
import os
import shutil

from lib.advisor import Advisor
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from dotenv import dotenv_values


               
def annotate_test(label):
    if uploaded_file is not None:
        st.session_state.annotations_test[st.session_state.current_test_file] = label
    st.session_state.annotated_test = pd.DataFrame(list(st.session_state.annotations_test.items()), columns = [str(select_col), 'class'])
    if st.session_state.test_hist.empty == False:
        st.session_state.annotated_test = st.session_state.test_hist.append(st.session_state.annotated_test).reset_index(drop=True) #
    st.session_state.test_sample = st.session_state.test_sample[~st.session_state.test_sample.isin([st.session_state.current_test_file])]
    if st.session_state.test_sample.empty == False:
        st.session_state.current_test_file = random.choice(st.session_state.test_sample.tolist())  

              
def annotate(label):
    st.session_state.annotations[st.session_state.current_file] = label  
    st.session_state.files = st.session_state.files[~st.session_state.files.isin([st.session_state.current_file])]
    if st.session_state.files.empty == False:
        st.session_state.current_file = random.choice(st.session_state.files.tolist())

        
def change_marked_value(df):
    with st.expander('–ò–∑–º–µ–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Ä–∞–º–∑–µ—Ç–∫–∏'):
        raw = st.text_input('–ù–æ–º–µ—Ä —Å—Ç—Ä–æ–∫–∏')
        new_class = st.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ –∫–ª–∞—Å—Å', class_list)
        if st.button('–ò–∑–º–µ–Ω–∏—Ç—å'):
            df.iloc[[int(raw)],[1]] = new_class     
    
    
def adjust_chunk_size():
    with st.sidebar.expander('–ò–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞'):
        incr_decr_tr = st.selectbox('', ('–£–≤–µ–ª–∏—á–∏—Ç—å', '–£–º–µ–Ω—å—à–∏—Ç—å'))
        num_fill_tr = st.text_input('–ù–∞ —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π?')
        
        if st.button('–ò–∑–º–µ–Ω–∏—Ç—å', key = 'add_chunk'): 
            if incr_decr_tr == '–£–º–µ–Ω—å—à–∏—Ç—å':
                st.session_state.chunk_size = st.session_state.chunk_size - int(num_fill_tr) 
                
                excess_chunk_sample = st.session_state.files.sample(n = int(num_fill_tr),  replace = False)
                st.session_state.files = st.session_state.files.drop(excess_chunk_sample.index).reset_index(drop = True)
                excess_chunk_sample = pd.merge(st.session_state.raw_data, excess_chunk_sample, on=str(select_col), how='right').drop_duplicates()
                st.session_state.input_df = st.session_state.input_df.append(excess_chunk_sample).reset_index(drop = True)
                st.session_state.current_file = random.choice(st.session_state.files.tolist())
                              
            else:
                st.session_state.chunk_size = st.session_state.chunk_size + int(num_fill_tr)               
                add_chunk = st.session_state.input_df[select_col].sample(n = int(num_fill_tr), replace = False)
                st.session_state.input_df = st.session_state.input_df.drop(add_chunk.index).reset_index(drop = True)
                st.session_state.files = st.session_state.files.append(add_chunk).reset_index(drop = True)
                st.session_state.current_file = random.choice(st.session_state.files.tolist())
                    
                    
def adjust_test_size():
    with st.sidebar.expander('–ò–∑–º–µ–Ω–∏—Ç—å —Ä–∞–∑–º–µ—Ä —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏'):
        incr_decr = st.selectbox('', ('–£–≤–µ–ª–∏—á–∏—Ç—å', '–£–º–µ–Ω—å—à–∏—Ç—å'), key = 'add_test')
        num_fill = st.text_input('–ù–∞ —Å–∫–æ–ª—å–∫–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π?', key = 'ad_test1')
        
        if st.button('–ò–∑–º–µ–Ω–∏—Ç—å', key = 'ad_test2'):           
            if incr_decr == '–£–º–µ–Ω—å—à–∏—Ç—å':
                excess_test_sample = st.session_state.test_sample.sample(n = int(num_fill), replace = False)
                st.session_state.test_sample = st.session_state.test_sample.drop(excess_test_sample.index).reset_index(drop = True)
                excess_test_sample = pd.merge(st.session_state.raw_data, excess_test_sample, on=str(select_col), how='right').drop_duplicates()
                st.session_state.input_df = st.session_state.input_df.append(excess_test_sample).reset_index(drop = True)
                st.session_state.current_test_file = random.choice(st.session_state.test_sample.tolist())
            
            else:
                add_test = st.session_state.input_df[select_col].sample(n = int(num_fill), replace = False)
                st.session_state.input_df = st.session_state.input_df.drop(add_test.index).reset_index(drop = True)
                st.session_state.test_sample = st.session_state.test_sample.append(add_test).reset_index(drop = True)
                st.session_state.current_test_file = random.choice(st.session_state.test_sample.tolist())

         
def concat_to_export(label1, inner_df, label2 = "", inner_df2 = "", label3 = "", inner_df3 = ""):
    inner_df['type_sample'] = label1
    st.session_state.upload_df['index_orig'] = st.session_state.upload_df.index
    inner_df = pd.merge(st.session_state.upload_df, inner_df, on=str(select_col), how='right').drop_duplicates()
    out_df = st.session_state.upload_df.drop(inner_df['index_orig'])
    
    if label2 != "":
        inner_df2['type_sample'] = label2
        inner_df2 = pd.merge(st.session_state.upload_df, inner_df2, on=str(select_col), how='right').drop_duplicates()
        out_df = out_df.drop(inner_df2['index_orig'])
        
        if label3 != "":
            inner_df3['type_sample'] = label3
            inner_df3 = pd.merge(st.session_state.upload_df, inner_df3, on=str(select_col), how='right').drop_duplicates()
            out_df = out_df.drop(inner_df3['index_orig'])
            out_df = inner_df.append([inner_df2, inner_df3, out_df]).reset_index(drop = True)  
            
        else:
            out_df = inner_df.append([inner_df2, out_df]).reset_index(drop = True)
    
    else:
        out_df = inner_df.append(out_df).reset_index(drop = True)
    
    out_df = out_df.drop(['index_orig'], axis=1)
    return out_df


def draw_metrics():
    with st.expander('–î–∏–Ω–∞–º–∏–∫–∞ –º–µ—Ç—Ä–∏–∫ –∫–∞—á–µ—Å—Ç–≤–∞ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ'): 
        if len(st.session_state.chunk_len) > 1:
            fig, ax = plt.subplots()
            sns.set_theme()
            ax = sns.lineplot(data = st.session_state.metrics_sum, ax = ax)
            #ax.xaxis.set_major_locator(ticker.MultipleLocator(st.session_state.chunk_size))
            ax.xaxis.set_major_formatter(ticker.ScalarFormatter())
            ax.yaxis.set_major_locator(ticker.MultipleLocator(0.1))
            ax.set_ylim(0, 1)
            ax.set(xlabel='–†–∞–∑–º–µ—á–µ–Ω–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π')
            st.pyplot(fig)             
          

def model_learn(marked_chunk, val_sam, sample_type):  
    if __name__ == '__main__':
        
        if page == '–ù–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)' or st.session_state.annotated_df.empty: # or = —Å—Ü–µ–Ω–∞—Ä–∏–∏ 2 –∏ 3 –≤ —Ä–µ–∂–∏–º–µ –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
            advisor = Advisor(
                vectorizer=TfidfVectorizer(max_features=10000),
                model=SVC(random_state=1234) 
            )    
            
        else:
            advisor = model_load

        marked_chunk.columns = [str(select_col), 'class']
        val_sam.columns = [str(select_col), 'class']       
        
        advisor.fit_vectorizer(marked_chunk[str(select_col)])
            
        try:
            advisor.fit_model(marked_chunk[str(select_col)], marked_chunk['class'])
     
        except ValueError:
            print('–†–∞–∑–º–µ—Ç—å—Ç–µ –±–æ–ª—å—à–µ —á–∞–Ω–∫–æ–≤!')

        score = advisor.classification_report(val_sam[str(select_col)], val_sam['class'])
        score_df = pd.DataFrame(score)
        
        report = pd.DataFrame(score).transpose()
        
        if sample_type == "valid":
            st.write("### –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–µ") 
        
        else:
            st.write("### –ö–∞—á–µ—Å—Ç–≤–æ –º–æ–¥–µ–ª–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–µ")
        
        st.table(report)
        
        score_df = score_df.iloc[[2], 2:5]
        score_df = score_df.add_prefix('f1_')
        st.session_state.metrics_sum = pd.concat([st.session_state.metrics_sum, score_df])
        st.session_state.chunk_len.append(len(marked_chunk))
        st.session_state.metrics_sum["chunk"] = st.session_state.chunk_len
        st.session_state.metrics_sum = st.session_state.metrics_sum.set_index('chunk')
        
        return advisor
                  
       
def markup_func(val_samp, test_samp):
    adjust_chunk_size()
    col1.write(st.session_state.current_file)

    with col2:
        if st.session_state.input_df.empty == False:
            st.write(
                "–†–∞–∑–º–µ—á–µ–Ω–æ:",
                st.session_state.chunk_size - len(st.session_state.files),
                "‚Äì –û—Å—Ç–∞–ª–æ—Å—å:",
                len(st.session_state.files),
            )
            for value in class_list:
                st.button(value, on_click = annotate, args=(value,))   
            
            st.write("### –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è")
            
            if st.session_state.annotated_df.empty: # –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
                annotated = pd.DataFrame(list(st.session_state.annotations.items()), columns = [str(select_col), 'class'])
                change_marked_value(annotated)
                st.dataframe(annotated)
                
            else: # –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è
                annotated = pd.DataFrame(list(st.session_state.annotations.items()), columns = [str(select_col), 'class'])
                annotated = st.session_state.annotated_df.append(annotated).reset_index(drop=True)
                change_marked_value(annotated)
                st.dataframe(annotated)                                   
            
            st.write(
            "–ù–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π –≤ –∫–æ—Ä–ø—É—Å–µ:",
            len(st.session_state.input_df)
            ) 
            
            if st.session_state.files.empty:
                st.success(
                f"üéà –ì–æ—Ç–æ–≤–æ! {len(st.session_state.annotations)} –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π —Ä–∞–∑–º–µ—á–µ–Ω–æ"
                )
                
                st.session_state.model = model_learn(annotated, val_samp, "valid")                
                st.session_state.files = st.session_state.model.predict_proba(st.session_state.input_df[select_col])
                st.session_state.files = st.session_state.files.sort_values(by='proba').head(st.session_state.chunk_size).reset_index(drop = True) 
                st.session_state.input_df = st.session_state.input_df.drop(st.session_state.files.index).reset_index(drop = True)
                st.session_state.files = st.session_state.files[select_col]
                st.session_state.current_file = random.choice(st.session_state.files.tolist())
                
                st.button('–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É (–≤—ã–≤–µ—Å—Ç–∏ —Å–ª–µ–¥—É—é—â–∏–π —á–∞–Ω–∫)')
                           
            if st.checkbox("–ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É:"):
                download = st.radio('', ('–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–∑–∂–µ', '–†–∞–∑–º–µ—Ç–∏—Ç—å –≤–µ—Å—å –∫–æ—Ä–ø—É—Å'))

                if download == '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å –ø–æ–∑–∂–µ': 
                    annotated.columns = [str(select_col), 'class']
                    output_df = concat_to_export('train', annotated, 'valid', val_samp, 'test', test_samp)
                    st.download_button("–í—ã–≥—Ä—É–∑–∏—Ç—å –∫–æ—Ä–ø—É—Å",  output_df.to_csv(index=False).encode('utf-8'), file_name = "train_marked.csv")
                    
                    if st.session_state.model != "": 
                        output_model = pickle.dumps(st.session_state.model, protocol=None)
                        st.download_button('–í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å', output_model, file_name = "model.bin")                

                else: 
                    annotated.columns = [str(select_col), 'class']
                    st.session_state.model = model_learn(annotated, test_samp, "test")
                    output_df = concat_to_export('train', annotated, 'valid', val_samp, 'test', test_samp)
                    output_df1 = output_df[output_df['class'].isnull()]
                    output_df = output_df.dropna()
                    output_df1['class'] = st.session_state.model.predict(output_df1[select_col])
                    output_df = output_df.append(output_df1).drop(['type_sample'], axis=1)
                    st.download_button("–í—ã–≥—Ä—É–∑–∏—Ç—å –∫–æ—Ä–ø—É—Å",  output_df.to_csv(index=False).encode('utf-8'), file_name = "corpus_marked.csv")

                    output_model = pickle.dumps(st.session_state.model, protocol=None)
                    st.download_button('–í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å', output_model, file_name = "model.bin")
                
        else:
            st.success(
                f"üéà –†–∞–º–∑–µ—Ç–∫–∞ –∫–æ—Ä–ø—É—Å–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å–µ–≥–æ —Ä–∞–∑–º–µ—á–µ–Ω–æ {len(st.session_state.annotations)} –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π"
            )
            obj = model_learn(annotated, test_samp)
            annotated.columns = [str(select_col), 'class']
            output_df = concat_to_export('train', annotated, 'valid', val_samp, 'test', test_samp)
            
            st.download_button("–í—ã–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π –∫–æ—Ä–ø—É—Å",  output_df.to_csv(index=False).encode('utf-8'), file_name = "corpus_marked.csv")
            
            output_model = pickle.dumps(st.session_state.model, protocol=None)
            st.download_button('–í—ã–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å', output_model, file_name = "model.bin")      
        
      
def markup_test():
    if st.session_state.test_sample.empty == False:
        adjust_test_size()
        col1.write(st.session_state.current_test_file)
        
        with col2:
            st.write(
                "–†–∞–∑–º–µ—á–µ–Ω–æ:",
                len(st.session_state.annotations_test),
                "‚Äì –û—Å—Ç–∞–ª–æ—Å—å:",
                len(st.session_state.test_sample),
            )
            for value in class_list:
                st.button(value, on_click = annotate_test, args=(value,))

            st.write("### –ê–Ω–Ω–æ—Ç–∞—Ü–∏—è")
            
            
            if st.session_state.test_hist.empty: # –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø—Ä–æ–µ–∫—Ç–∞
                st.session_state.annotated_test = pd.DataFrame(list(st.session_state.annotations_test.items()), columns = [str(select_col), 'class'])
                change_marked_value(st.session_state.annotated_test)
                st.dataframe(st.session_state.annotated_test)                

            else: # –¥–ª—è –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏—è 
                if st.session_state.annotated_test.empty:
                    st.session_state.annotated_test = st.session_state.test_hist.append(st.session_state.annotated_test).reset_index(drop=True) 
                change_marked_value(st.session_state.annotated_test)
                st.dataframe(st.session_state.annotated_test)
                
            st.write(
            "–ù–µ—Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π –≤ –∫–æ—Ä–ø—É—Å–µ:",
            len(st.session_state.input_df)
            )
        
        output_df = concat_to_export('test', st.session_state.annotated_test)
        st.download_button("–ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É (–≤—ã–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç)",  output_df.to_csv(index=False).encode('utf-8'), file_name = "test_marked.csv")                          
    
    else:
        if st.session_state.annotations == {}:
            st.success(
                    f"üéà –†–∞–º–∑–µ—Ç–∫–∞ —Ç–µ—Å—Ç–æ–≤–æ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏ –∑–∞–≤–µ—Ä—à–µ–Ω–∞! –í—Å–µ–≥–æ —Ä–∞–∑–º–µ—á–µ–Ω–æ {len(st.session_state.annotations_test)} –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π"
                )

            if st.session_state.val_sample.empty:
                st.session_state.val_sample = st.session_state.annotated_test.sample(frac = 0.5) 
                st.session_state.test_out = st.session_state.annotated_test.drop(st.session_state.val_sample.index).reset_index(drop = True)
                st.session_state.val_sample = st.session_state.val_sample.reset_index(drop = True)
                
            annotated_test = st.session_state.test_out
            valid_sample = st.session_state.val_sample
            output_df = concat_to_export('test', annotated_test, 'valid', valid_sample) 
            st.download_button("–ó–∞–≤–µ—Ä—à–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É (–≤—ã–≥—Ä—É–∑–∏—Ç—å —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π —Ç–µ—Å—Ç)",  output_df.to_csv(index=False).encode('utf-8'), file_name = "testval_marked.csv")            

        if st.checkbox('–ü—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ —Ä–∞–∑–º–µ—Ç–∫–µ —á–∞–Ω–∫–æ–≤ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏'):
            with st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É"):
                st.table(st.session_state.test_out[[str(select_col), 'class']])
            with st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∞–ª –≤—ã–±–æ—Ä–∫—É"):
                st.table(st.session_state.val_sample[[str(select_col), 'class']])

            valid_sample = st.session_state.val_sample[[str(select_col), 'class']]
            annotated_test = st.session_state.test_out[[str(select_col), 'class']]
            markup_func(valid_sample, annotated_test)
    
 

st.markdown(""" <style>
#MainMenu {visibility: hidden;}
footer {visibility: hidden;}d
</style> """, unsafe_allow_html=True)

if "entkey" not in st.session_state:
    st.session_state.entkey = ""

if st.session_state.entkey == "":
    st.session_state.placeholder1 = st.sidebar.empty()
    st.session_state.placeholder2 = st.sidebar.empty()
    st.session_state.placeholder3 = st.sidebar.empty()
    st.session_state.placeholder1.title('–ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è')
    username = st.session_state.placeholder2.text_input('–õ–æ–≥–∏–Ω')
    st.session_state.username = username
    password = st.session_state.placeholder3.text_input('–ü–∞—Ä–æ–ª—å', type='password')
    st.session_state.password = password
        
if st.session_state.username == 'cpur_user' and st.session_state.password == '6DTE3Bkeho2m':
    st.session_state.placeholder1.empty()
    st.session_state.placeholder2.empty()
    st.session_state.placeholder3.empty()
    st.session_state.entkey = "something"

    page = st.sidebar.radio('–•–æ—Ç–∏—Ç–µ –ø—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É?', ('–ù–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)', '–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–±–æ—Ç—É'))

    if "test_sample" and "current_test_file" and "files" and "current_file" and "chunk_size" not in st.session_state:
        st.session_state.test_sample = pd.DataFrame()
        st.session_state.current_test_file = ''
        st.session_state.files = pd.DataFrame()
        st.session_state.current_file = ''
        st.session_state.chunk_size = ''

    if page == '–ù–æ–≤—ã–π –ø—Ä–æ–µ–∫—Ç (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é)':
        st.sidebar.header('–ó–∞–¥–∞–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–∑–º–µ—Ç–∫–∏')
        uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –∫–æ—Ä–ø—É—Å —Ç–µ–∫—Å—Ç–æ–≤ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ csv):", type=["csv"])

        if uploaded_file is not None:
            upload_df = pd.read_csv(uploaded_file)
            select_col = st.sidebar.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏', upload_df.columns)
            raw_data = upload_df.drop_duplicates(subset=[select_col]).reset_index(drop = True)
            test_val_size = st.sidebar.number_input('–ö–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ—Ä–ø—É—Å–∞ –≤—ã –≥–æ—Ç–æ–≤—ã –æ—Ç–¥–∞—Ç—å –ø–æ–¥ —Ç–µ—Å—Ç–æ–≤—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏?', min_value=20.0, max_value=30.0, value=20.0, step=1.0)
            st.sidebar.markdown(f'<p style="background-color:pink;font-size:15px;border-radius:2%;"> –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π —Ä–∞–∑–º–µ—Ä: <strong>>20% </strong> –∫–æ—Ä–ø—É—Å–∞</p>', unsafe_allow_html=True)

            class_num = st.sidebar.number_input('–°–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–æ–≤ –≤—ã —Ö–æ—Ç–∏—Ç–µ –≤—ã–¥–µ–ª–∏—Ç—å?', min_value=2, max_value=10, value=2, step=1)
            i = 1
            class_list = []
            keys = []
            key = 'a'
            while i <= class_num:
                class_list.append(st.sidebar.text_input("–í–≤–µ–¥–∏—Ç–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ " + str(i), key = key))
                keys.append(i)
                i += 1
                key *= 2 

            chunk_size = st.sidebar.number_input('–°–∫–æ–ª—å–∫–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–∏–Ω —á–∞–Ω–∫ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏?', min_value=500, max_value=5000, value=500, step=50)
            chunk = raw_data[select_col].sample(n = chunk_size).reset_index(drop = True) 
            input_df = raw_data.drop(chunk.index).reset_index(drop = True)
            #mix_words = st.sidebar.selectbox('–ò–∑–º–µ–Ω–∏—Ç—Å—è –ª–∏ —Å–º—ã—Å–ª —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∫–æ—Ä–ø—É—Å–∞, –µ—Å–ª–∏ –≤ –Ω–∏—Ö –ø–µ—Ä–µ–º–µ—à–∞—Ç—å —Å–ª–æ–≤–∞?', ('–î–∞', '–ù–µ—Ç'))

            if "upload_df" and "annotations" and "annotated_df" and "model" not in st.session_state:
                st.session_state.upload_df = upload_df
                st.session_state.annotations = {}
                st.session_state.raw_data = raw_data
                st.session_state.annotated_df = pd.DataFrame()
                st.session_state.model = ""        

            if "val_sample" and "test_out" and "annotations_test" and "current_test_file" and "annotated_test" and "metrics_sum" and "chunk_len" and "test_hist" not in st.session_state:
                st.session_state.val_sample = pd.DataFrame()
                st.session_state.test_out = pd.DataFrame()
                st.session_state.annotations_test = {}
                st.session_state.annotated_test = pd.DataFrame()
                st.session_state.metrics_sum = pd.DataFrame() 
                st.session_state.chunk_len = []
                st.session_state.test_hist = pd.DataFrame() 


            if st.sidebar.checkbox('–ü—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ —Ä–∞–∑–º–µ—Ç–∫–µ —Ç–µ—Å—Ç–æ–≤–æ–π –≤—ã–±–æ—Ä–∫–∏') == False:
                st.session_state.test_sample = input_df[select_col].sample(frac = test_val_size/100)
                input_df = input_df.drop(st.session_state.test_sample.index).reset_index(drop = True)
                st.session_state.input_df = input_df
                st.session_state.raw_data = raw_data
                st.session_state.test_sample = st.session_state.test_sample.reset_index(drop = True)
                st.session_state.current_test_file = st.session_state.test_sample.iloc[0]
                st.session_state.files = chunk
                st.session_state.current_file = chunk.iloc[0]
                st.session_state.chunk_size = chunk_size

            else:
                st.write("")
                col1, col2 = st.columns(2)
                markup_test()     
                draw_metrics()       

    else:
        st.sidebar.header('–ó–∞–¥–∞–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ä–∞–∑–º–µ—Ç–∫–∏')
        uploaded_file = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã–π –∫–æ—Ä–ø—É—Å —Ç–µ–∫—Å—Ç–æ–≤ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ csv):", type=["csv"])
        if uploaded_file is not None: 
            upload_df = pd.read_csv(uploaded_file)
            select_col = st.sidebar.selectbox('–í—ã–±–µ—Ä–∏—Ç–µ –∫–æ–ª–æ–Ω–∫—É –¥–∞—Ç–∞—Ñ—Ä–µ–π–º–∞ –¥–ª—è —Ä–∞–∑–º–µ—Ç–∫–∏', upload_df.columns)
            raw_data = upload_df.drop_duplicates(subset=[select_col]).reset_index(drop = True) #
            annotated_df = raw_data.dropna()
            raw_data = raw_data.drop(['class', 'type_sample'], axis=1)
            input_df = raw_data.drop(annotated_df.index).reset_index(drop = True)
            annotated_train = annotated_df[annotated_df['type_sample'] == 'train'].reset_index(drop=True)
            samples_needed = {'train', 'test', 'valid'}
            samples_present = set(annotated_df['type_sample'])

            if samples_needed.issubset(samples_present) == False:
                missed_samp = samples_needed - samples_present

                if 'train' in missed_samp:
                    st.sidebar.warning(f'–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≤ –≤–∞—à–µ–º –∫–æ—Ä–ø—É—Å–µ –Ω–µ —Ä–∞–∑–º–µ—á–µ–Ω–∞ –æ–±—É—á–∞—é—â–∞—è –≤—ã–±–æ—Ä–∫–∞')

                if 'valid' in missed_samp:
                    st.sidebar.warning(f'–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≤ –≤–∞—à–µ–º –∫–æ—Ä–ø—É—Å–µ –Ω–µ —Ä–∞–∑–º–µ—á–µ–Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–∞—è –≤—ã–±–æ—Ä–∫–∞')
                    valid_sample = None
                else:
                    valid_sample = annotated_df[annotated_df['type_sample'] == 'valid'].reset_index(drop = True)
                    valid_sample = valid_sample[[str(select_col), 'class']]

                if 'test' in missed_samp:
                    st.sidebar.warning(f'–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≤ –≤–∞—à–µ–º –∫–æ—Ä–ø—É—Å–µ –Ω–µ —Ä–∞–∑–º–µ—á–µ–Ω–∞ —Ç–µ—Å—Ç–æ–≤–∞—è –≤—ã–±–æ—Ä–∫–∞')
                else:
                    annotated_test = annotated_df[annotated_df['type_sample'] == 'test'].reset_index(drop = True)
                    annotated_test = annotated_test[[str(select_col), 'class']]

            else:
                valid_sample = annotated_df[annotated_df['type_sample'] == 'valid'].reset_index(drop = True)
                valid_sample = valid_sample[[str(select_col), 'class']]
                annotated_test = annotated_df[annotated_df['type_sample'] == 'test'].reset_index(drop = True)
                annotated_test = annotated_test[[str(select_col), 'class']]                        

            chunk_size = st.sidebar.number_input('–°–∫–æ–ª—å–∫–æ –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å –æ–¥–∏–Ω —á–∞–Ω–∫ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏?', min_value=500, max_value=5000, value=500, step=50)
            chunk = input_df[select_col].sample(n = chunk_size).reset_index(drop = True)
            input_df = input_df.drop(chunk.index).reset_index(drop = True)
            class_list = list(annotated_df['class'].unique())
            class_list = [str(x) for x in class_list]
            class_list = [x for x in class_list if x != 'nan'] 
            if len(class_list) > 1:
                st.sidebar.info(f'–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–π –∫–æ—Ä–ø—É—Å —Å–æ–¥–µ—Ä–∂–∏—Ç —Å–ª–µ–¥—É—é—â–∏–µ –∫–ª–∞—Å—Å—ã: {str(class_list)[1:-1]}')  
            else:
                st.sidebar.warning('–ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: –≤ –≤–∞—à–µ–º –∫–æ—Ä–ø—É—Å–µ –≤—ã–¥–µ–ª–µ–Ω —Ç–æ–ª—å–∫–æ –æ–¥–∏–Ω –∫–ª–∞—Å—Å –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π')

            class_num = st.sidebar.number_input('–°–∫–æ–ª—å–∫–æ –∫–ª–∞—Å—Å–æ–≤ –≤—ã —Ö–æ—Ç–∏—Ç–µ –¥–æ–±–∞–≤–∏—Ç—å?', min_value=0, max_value=10, value=0, step=1)
            i = 1
            keys = []
            key = 'a'
            while i <= class_num:
                class_list.append(st.sidebar.text_input("–í–≤–µ–¥–∏—Ç–µ –æ–±–æ–∑–Ω–∞—á–µ–Ω–∏–µ –∫–ª–∞—Å—Å–∞ " + str(i), key = key))
                keys.append(i)
                i += 1
                key *= 2 
            #mix_words = st.sidebar.selectbox('–ï—Å–ª–∏ –ø–µ—Ä–µ–º–µ—à–∞—Ç—å —Å–ª–æ–≤–∞ –≤ —ç–ª–µ–º–µ–Ω—Ç–∞—Ö –∫–æ—Ä–ø—É—Å–∞, –∏—Ö —Å–º—ã—Å–ª –∏–∑–º–µ–Ω–∏—Ç—Å—è?', ('–î–∞', '–ù–µ—Ç'))

            if "upload_df" and "annotations" and "annotated_df" not in st.session_state:
                st.session_state.upload_df = upload_df.drop(columns=['type_sample', 'class'])
                st.session_state.annotations = {} 
                st.session_state.raw_data = raw_data
                st.session_state.annotated_df = annotated_train[[str(select_col), 'class']]

            if "metrics_sum" and "val_sample" and "test_out" and "chunk_len" not in st.session_state:
                st.session_state.val_sample = pd.DataFrame()
                st.session_state.test_out = pd.DataFrame()
                st.session_state.metrics_sum = pd.DataFrame() 
                st.session_state.chunk_len = []

            if "annotations_test" and "test_hist" not in st.session_state:
                st.session_state.annotations_test = {}
                st.session_state.annotated_test = pd.DataFrame()
                st.session_state.test_hist = annotated_test

        if uploaded_file is not None: 

            if st.session_state.annotated_df.empty is False:   # —Å—Ü–µ–Ω–∞—Ä–∏–π 1 - –µ—Å—Ç—å train
                uploaded_model = st.sidebar.file_uploader("–ó–∞–≥—Ä—É–∑–∏—Ç–µ –¥–∞–º–ø –º–æ–¥–µ–ª–∏ (–≤ —Ñ–æ—Ä–º–∞—Ç–µ bin):", type=["bin"])   

                if uploaded_model is not None:
                    os.makedirs('tempDir', exist_ok=True)
                    with open(os.path.join("tempDir", uploaded_model.name), "wb") as f: 
                        f.write(uploaded_model.getbuffer()) 
                    model_load = pickle.load(open(os.path.join("tempDir", uploaded_model.name), 'rb'))
                    shutil.rmtree('tempDir/', ignore_errors=True)   

                    if "model" not in st.session_state:
                        st.session_state.model = model_load

                    if st.sidebar.checkbox('–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏') == False:
                        st.session_state.annotated_df = annotated_train[[str(select_col), 'class']]
                        st.session_state.files = chunk
                        st.session_state.current_file = chunk.iloc[0]
                        st.session_state.chunk_size = chunk_size
                        st.session_state.input_df = input_df

                    else:    
                        st.write("")
                        col1, col2 = st.columns(2)
                        markup_func(valid_sample, annotated_test)

                        with st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É"):
                            st.table(annotated_test[[str(select_col), 'class']])
                        with st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∞–ª –≤—ã–±–æ—Ä–∫—É"):
                            st.table(valid_sample[[str(select_col), 'class']])                                
                        draw_metrics()

            else:

                if valid_sample is not None: # —Å—Ü–µ–Ω–∞—Ä–∏–π 2 - –µ—Å—Ç—å test –∏ val
                    if "model" not in st.session_state:
                        st.session_state.model = ""
                        st.session_state.annotated_df = pd.DataFrame()

                    if st.sidebar.checkbox('–ü—Ä–∏—Å—Ç—É–ø–∏—Ç—å –∫ —Ä–∞–∑–º–µ—Ç–∫–µ –æ–±—É—á–∞—é—â–µ–π –≤—ã–±–æ—Ä–∫–∏') == False:
                        st.session_state.files = chunk
                        st.session_state.current_file = chunk.iloc[0]
                        st.session_state.chunk_size = chunk_size
                        st.session_state.input_df = input_df

                    else:    
                        st.write("")
                        col1, col2 = st.columns(2)
                        markup_func(valid_sample, annotated_test)

                        with st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å —Ç–µ—Å—Ç–æ–≤—É—é –≤—ã–±–æ—Ä–∫—É"):
                            st.table(annotated_test[[str(select_col), 'class']])
                        with st.expander("–ü–æ—Å–º–æ—Ç—Ä–µ—Ç—å –≤–∞–ª –≤—ã–±–æ—Ä–∫—É"):
                            st.table(valid_sample[[str(select_col), 'class']])
                        draw_metrics()  

                else:    # —Å—Ü–µ–Ω–∞—Ä–∏–π 3 - –µ—Å—Ç—å —Ç–æ–ª—å–∫–æ —Ç–µ—Å—Ç (i.e. –Ω–∞–¥–æ –¥–æ—Ä–∞–∑–º–µ—Ç–∏—Ç—å)

                    if "model" not in st.session_state:
                        st.session_state.model = ""
                        st.session_state.annotated_df = pd.DataFrame()

                    st.sidebar.markdown("–ö–∞–∫–æ–π –ø—Ä–æ—Ü–µ–Ω—Ç –∫–æ—Ä–ø—É—Å–∞ –≤—ã –≥–æ—Ç–æ–≤—ã –æ—Ç–¥–∞—Ç—å –ø–æ–¥ —Ç–µ—Å—Ç–æ–≤—É—é –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω—É—é –≤—ã–±–æ—Ä–∫–∏?")
                    minimum_value = 20.0 - (len(st.session_state.test_hist)/len(raw_data)*100)
                    test_val_size = st.sidebar.number_input('(—Å —É—á—ë—Ç–æ–º —Ä–∞–∑–º–µ—á–µ–Ω–Ω—ã—Ö –∑–∞–ø–æ–ª–Ω–µ–Ω–∏–π)', min_value=minimum_value, max_value=30.0, value=minimum_value, step=1.0)
                    st.sidebar.info(f'–¢–µ—Å—Ç–æ–≤–∞—è –∏ –≤–∞–ª–∏–¥-–∞—è –≤—ã–±–æ—Ä–∫–∏ —Å–µ–π—á–∞—Å —Å–æ—Å—Ç–∞–≤–ª—è—é—Ç ~ {round(len(st.session_state.test_hist)/len(raw_data)*100, 2)} % –∫–æ—Ä–ø—É—Å–∞')
                    st.sidebar.markdown(f'<p style="background-color:pink;font-size:15px;border-radius:2%;"> –†–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–π —Å–æ–≤–æ–∫—É–ø–Ω—ã–π —Ä–∞–∑–º–µ—Ä: <strong>>20% </strong> –∫–æ—Ä–ø—É—Å–∞</p>', unsafe_allow_html=True)

                    if st.sidebar.checkbox('–ü—Ä–æ–¥–æ–ª–∂–∏—Ç—å —Ä–∞–∑–º–µ—Ç–∫—É —Ç–µ—Å—Ç–æ–≤–æ–π –∏ –≤–∞–ª–∏–¥–∞—Ü–∏–æ–Ω–Ω–æ–π –≤—ã–±–æ—Ä–∫–∏') == False:
                        st.session_state.raw_data = raw_data
                        st.session_state.files = chunk
                        st.session_state.current_file = chunk.iloc[0]
                        st.session_state.chunk_size = chunk_size
                        st.session_state.test_sample = input_df[select_col].sample(frac = test_val_size/100)
                        st.session_state.input_df = input_df.drop(st.session_state.test_sample.index).reset_index(drop = True)
                        st.session_state.test_sample = st.session_state.test_sample.reset_index(drop = True)
                        st.session_state.test_hist = annotated_df[annotated_df['type_sample'] == 'test'].reset_index(drop = True)
                        st.session_state.test_hist = st.session_state.test_hist[[str(select_col), 'class']]
                        st.session_state.current_test_file = st.session_state.test_sample.iloc[0]

                    else:
                        st.write("")
                        col1, col2 = st.columns(2)
                        markup_test()  
                        draw_metrics()

else:
    if username and password != "":
        st.sidebar.error("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω—ã–π –ª–æ–≥–∏–Ω –∏–ª–∏ –ø–∞—Ä–æ–ª—å")
